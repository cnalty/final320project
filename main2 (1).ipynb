{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://s.abcnews.com/images/Business/GTY_ncaa_logo_ml_140121_33x16_992.jpg width= \"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Predicting Wins in NCAA Men's Basketball </center>\n",
    "<center> Derek Lore, Christopher Nalty, Michael Stephanus </center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <center> Introduction </center>\n",
    "\n",
    "The National Collegiate Athletic Association (<a href= \"https://www.ncaa.com/\">NCAA</a>) is a nonprofit organization dedicated to the well-being and lifelong success of college athletes. The NCAA was built in 1910 and they essentially  regulates competitions between universities and colleges. They organize athletic programs such as basketball, footbal, soccer, basketball, etc. Currently 1,117 college and universities are a part of the NCAA.\n",
    "\n",
    "In this tutorial, we will be focusing on basketball. We will collect data about an entire NCAA season and build predictive models whether a team win or lose. We will start by getting the necessary datas to build our models. We will be search for datasets that contain specific statisics that occurs in a basketball game such as the number of turn overs, assists, blocks, rebounds, field goal percentage, etc. We will tidy the data and we will try to find correlations between each statistic and a team's winrate. This all leads up to the purpose of this tutorial, which is whether we can predict whether a team will win a game if they have a certain amount of rebounds, assists, turnovers, etc. Hopefully this tutorial can provide all of you basketball enthusiasts an insight of how these datas can predict the outcome of a game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. <a href=\"#Gathering the Data\">Gathering the Data</a>\n",
    "<ul><li>1.1 <a href=\"#Team Box Scores\">Team Box Scores</a></li>\n",
    "    <li>1.2 <a href=\"#Team Ranks\">Team Ranks</a></li>\n",
    "    <li>1.3 <a href=\"#Game Statistics\">Game Statistics</a></li></ul>\n",
    "2. <a href=\"#Data Cleaning\">Data Cleaning</a>\n",
    "<ul><li>2.1 <a href=\"#Team Box Scores Cleaning\">Team Box Scores Cleaning</a>     </li>\n",
    "    <li>2.2 <a href=\"#Team Ranks Cleaning\">Team Ranks Cleaning</a></li>\n",
    "    <li>2.3 <a href=\"#Game Statistics Cleaning\">Game Statistics Cleaning</a>     </li>\n",
    "    <li>2.4 <a href=\"#Maping The Names\">Maping The Names</a></li></ul>\n",
    "3. <a href=\"#Exploratory Data Analysis\">Exploratory Data Analysis</a>\n",
    "<ul><li>3.1 <a href=\"#Number One Ranked Teams\">Number One Ranked Teams</a>       </li>\n",
    "    <li>3.2 <a href=\"#Field Goal Percentage Graph\">Field Goal Percentage Graph</a></li>\n",
    "    <li>3.3 <a href=\"#Average Statistics Graph\">Average Statistics Graph</a></li>\n",
    "    <li>3.4 <a href=\"#Statisics VS Win Percentage\">Statisics VS Win Percentage</a></li></ul>\n",
    "4. <a href=\"#Machine Learning\">Machine Learning</a>\n",
    "5. <a href=\"#Conclusion\">Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><a id=\"Gathering the Data\">Gathering the Data</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Team Box Scores\">1.1 Team Box Scores</a>\n",
    "\n",
    "The First piece of data we're going to gather is all of the game results for Division 1 games in the 2018-2019 season. \n",
    "We're going to get that data from a site called [Sports Reference](https://www.sports-reference.com/cbb/boxscores/). \n",
    "This site formats there urls for boxscore to include the month, day, and year you're looking at. Using this we can create\n",
    "a loop do go through all the dates in the season and download the box scores for each game. We add a short sleep after each day\n",
    "since we're sending a lot get requests to prevent any connection interruptions on either end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         date   win_team       lose_team win_score lose_score\n0  11/06/2018     Kansas  Michigan State        92         87\n1  11/06/2018       Duke        Kentucky       118         84\n2  11/06/2018    Gonzaga     Idaho State       120         79\n3  11/06/2018   Virginia          Towson        73         42\n4  11/06/2018  Tennessee    Lenoir-Rhyne        86         41",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>win_team</th>\n      <th>lose_team</th>\n      <th>win_score</th>\n      <th>lose_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11/06/2018</td>\n      <td>Kansas</td>\n      <td>Michigan State</td>\n      <td>92</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11/06/2018</td>\n      <td>Duke</td>\n      <td>Kentucky</td>\n      <td>118</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11/06/2018</td>\n      <td>Gonzaga</td>\n      <td>Idaho State</td>\n      <td>120</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11/06/2018</td>\n      <td>Virginia</td>\n      <td>Towson</td>\n      <td>73</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11/06/2018</td>\n      <td>Tennessee</td>\n      <td>Lenoir-Rhyne</td>\n      <td>86</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "box_scores = pd.DataFrame(columns=[\"date\", \"win_team\", \"lose_team\", \"win_score\", \"lose_score\"])\n",
    "\n",
    "#The format of the URL. we will continue to increment the month, day, and year\n",
    "url_format = \"https://www.sports-reference.com/cbb/boxscores/index.cgi?month={}&day={}&year={}\"\n",
    "for y in [2018, 2019]:\n",
    "    months = []\n",
    "    if y == 2018:\n",
    "        months = [11, 12]\n",
    "    else:\n",
    "        months = [1, 2, 3, 4]\n",
    "    \n",
    "    for m in months:\n",
    "        days = range(1,32)\n",
    "        for d in days:\n",
    "            url = url_format.format(str(m),str(d),str(y))\n",
    "            r = requests.get(url)\n",
    "\n",
    "            root = BeautifulSoup(r.content)\n",
    "            root.prettify()\n",
    "            \n",
    "            #format the months and days so that they are always 2 digits\n",
    "            mon = str(m)\n",
    "            day = str(d)\n",
    "            if (m < 10):\n",
    "                mon = \"0\" + mon\n",
    "            if (d < 10):\n",
    "                day = \"0\" + day\n",
    "            \n",
    "            date = str(mon) + \"/\" + str(day) + \"/\" + str(y)\n",
    "    \n",
    "            #game_summary nohover contains all the table for each match\n",
    "            #we will iterate through all the tables in the website and parse them one by one\n",
    "            for i in root.find_all(\"div\", class_=\"game_summary nohover\"):\n",
    "                loser = i.find(\"tr\", class_=\"loser\")\n",
    "                lose_team = loser.find(\"a\").getText()\n",
    "                lose_score = loser.find(\"td\", class_=\"right\").getText()\n",
    "    \n",
    "                winner = i.find(\"tr\", class_=\"winner\")\n",
    "                win_team = winner.find(\"a\").getText()\n",
    "                win_score = winner.find(\"td\", class_=\"right\").getText()\n",
    "                \n",
    "                box_scores = box_scores.append({\"date\":date, \"win_team\":win_team, \"lose_team\":lose_team, \"win_score\":win_score, \"lose_score\":lose_score}, ignore_index=True)\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "\n",
    "box_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a id=\"Team Ranks\">1.2 Team Ranks</a>\n",
    "\n",
    "The next piece of data we're going to gather is the ranks for each team from the ap polls of each week. We're also going\n",
    "get this information from [Sports Reference](https://www.sports-reference.com/cbb/seasons/2019-polls.html). This site\n",
    "has a csv formatted table we can just copy and paste into a file and read with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          School    Conf   Pre  11/12  11/19  11/26  12/03  12/10  12/17  \\\n0  Arizona State  Pac-12   NaN    NaN    NaN    NaN   20.0   20.0   18.0   \n1         Auburn     SEC  11.0    9.0    8.0    8.0    8.0    8.0    7.0   \n2        Buffalo     MAC   NaN   25.0   22.0   21.0   17.0   14.0   14.0   \n3     Cincinnati     AAC   NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n4        Clemson     ACC  22.0   19.0   16.0    NaN    NaN    NaN    NaN   \n\n   12/24  ...  01/14  01/21  01/28  02/04  02/11  02/18  02/25  03/04  03/11  \\\n0   17.0  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n1   12.0  ...   14.0   16.0    NaN    NaN    NaN    NaN    NaN    NaN   22.0   \n2   21.0  ...   16.0   14.0   18.0   23.0   25.0   25.0   21.0   19.0   18.0   \n3    NaN  ...    NaN    NaN    NaN   25.0    NaN    NaN   23.0   20.0   24.0   \n4    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n\n   Final  \n0    NaN  \n1   14.0  \n2   15.0  \n3   22.0  \n4    NaN  \n\n[5 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>School</th>\n      <th>Conf</th>\n      <th>Pre</th>\n      <th>11/12</th>\n      <th>11/19</th>\n      <th>11/26</th>\n      <th>12/03</th>\n      <th>12/10</th>\n      <th>12/17</th>\n      <th>12/24</th>\n      <th>...</th>\n      <th>01/14</th>\n      <th>01/21</th>\n      <th>01/28</th>\n      <th>02/04</th>\n      <th>02/11</th>\n      <th>02/18</th>\n      <th>02/25</th>\n      <th>03/04</th>\n      <th>03/11</th>\n      <th>Final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Arizona State</td>\n      <td>Pac-12</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>18.0</td>\n      <td>17.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Auburn</td>\n      <td>SEC</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>12.0</td>\n      <td>...</td>\n      <td>14.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Buffalo</td>\n      <td>MAC</td>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>22.0</td>\n      <td>21.0</td>\n      <td>17.0</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>21.0</td>\n      <td>...</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>18.0</td>\n      <td>23.0</td>\n      <td>25.0</td>\n      <td>25.0</td>\n      <td>21.0</td>\n      <td>19.0</td>\n      <td>18.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cincinnati</td>\n      <td>AAC</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>25.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Clemson</td>\n      <td>ACC</td>\n      <td>22.0</td>\n      <td>19.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 22 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "ranks = pd.read_csv(\"apranks.csv\") # found here https://www.sports-reference.com/cbb/seasons/2019-polls.html\n",
    "\n",
    "ranks.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a id=\"Game Statistics\">1.3 Game Statistics</a>\n",
    "\n",
    "The last piece of data we need to do is to acquire all of the team statistical data by week from the NCAA website. This way\n",
    "we can use to date accurate data for training and validation of our prediction model later on. Using only end of season statistics\n",
    "could have an effect on the prediction since teams stats will change as a season progresses. The data we're going to be using can be located at [http://web1.ncaa.org/stats/StatsSrv/rankings?sportCode=MBB]. This page requires us to do some clicking, \n",
    "and doesn't have all of the stats centralized in one csv. So to automate this we will use selenium, instead of doing ~12000 \n",
    "clicks ourselves. To do this we used the chrome based webdriver in selenium, to run this script you will need the \n",
    "[ChromeDriver](https://chromedriver.chromium.org/downloads). Once we have this installed we can now the following script \n",
    "to download every team stat available from every date of the 2018-2019 Men's Basketball season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "/home/chris/git/final320project/stats\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/chris/git/final320project/venv/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: use options instead of chrome_options\n",
      "  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "prefs = {'download.default_directory' : r'/home/chris/git/final320project/stats'}\n",
    "print(prefs['download.default_directory'])\n",
    "options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "driver = webdriver.Chrome(\"/home/chris/Downloads/chromedriver\", chrome_options=options) # change this to where ever your driver is\n",
    "\n",
    "# select division one button, since that's all we care about, will stay persistent\n",
    "driver.get(\"http://web1.ncaa.org/stats/StatsSrv/rankings?sportCode=MBB\")\n",
    "div1 = driver.find_element_by_xpath(\"/html/body/form/table[3]/tbody/tr[2]/td/select/option[2]\").click()\n",
    "week_base = \"/html/body/form/table[3]/tbody/tr[5]/td/select/option[{}]\" # base string for selecting week\n",
    "stats_base = \"/html/body/form/table[3]/tbody/tr[10]/td/select/option[{}]\" # base for stats\n",
    "\n",
    "for i in range(2, 142):\n",
    "    driver.find_element_by_xpath(week_base.format(i)).click()\n",
    "    for j in range(3, 33):\n",
    "        driver.find_element_by_xpath(stats_base.format(j)).click()\n",
    "        driver.find_element_by_xpath(\"/html/body/form/table[3]/tbody/tr[13]/td/input[4]\").click()\n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we need to load all of this data into dataframes to use. Since for win prediction we're going to be looking at\n",
    "stats by week, and pandas doesn't work well with relational databases, we're going to use a dictionary of dataframes as\n",
    "a representation of our relational database. The dictionary keys will act like foreign keys to a respective dataframes.\n",
    "\n",
    "<ol type=\"1\">\n",
    "    <li>To load the data, first we create a data dictionary. This will store multiple dataframes used to store team statistics for each date, using the date as the key in the dictionary.</li><br>\n",
    "    <li>We then walk the directory with the dataframes in it, opening each of the near-4,000 CSV files. However, the CSV files are in an imperfect format, so certain lines must be ignored. We found that lines 1 - 10 and line numbers greater than 363 were not useful in each file. The useful\n",
    "lines of the CSV file are stored in a string, which is parsed by pandas.read_csv to convert the CSV into a pandas dataframe.</li><br>\n",
    "    <li>We then must determine if the date has been seen before, since many of the statistics and information are \n",
    "spread between multiple files. If it has been seen before, we add it to the dataframe corresponding to that date, otherwise we add it to the dictionary as a new date. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "dfs = {}\n",
    "# walk the files saved from the data download\n",
    "\n",
    "for _, _, files in os.walk('stats'):\n",
    "    for file in files:\n",
    "        csv = \"\"\n",
    "        s = \"\"\n",
    "        # open the file and create a new string with only the csv contents\n",
    "        #print(file)\n",
    "        with open(os.path.join(\"stats/\", file), 'r') as f:\n",
    "            s = f.read()\n",
    "            i = 0\n",
    "            date = \"\"\n",
    "            for line in s.splitlines():\n",
    "                if i == 8:\n",
    "                    date = line[14:]\n",
    "                if (i > 10 and i < 363 or i == 364 or i == 365) and \",\" in line:\n",
    "                    csv += line+\"\\n\"\n",
    "                i = i + 1\n",
    "        if date in dfs:\n",
    "            ndata = pd.read_csv(io.StringIO(csv))\n",
    "            for c1 in dfs[date].columns:\n",
    "                if c1 in ndata.columns and c1 != \"Name\":\n",
    "                    del ndata[c1]\n",
    "            dfs[date] = dfs[date].merge(ndata)\n",
    "        else:\n",
    "            dfs[date] = pd.read_csv(io.StringIO(csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><a id=\"Cleaning and Tidying the Data\">Cleaning and Tidying the Data</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a id=\"Team Box Scores Cleaning\">2.1 Team Box Scores Cleaning</a>\n",
    "\n",
    "The Data for Box Scores is already Clean and Tidy, it's clear how to access all of the games with well organized columns and rows.\n",
    "So, we can leave this dataframe as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         date   win_team       lose_team win_score lose_score\n0  11/06/2018     Kansas  Michigan State        92         87\n1  11/06/2018       Duke        Kentucky       118         84\n2  11/06/2018    Gonzaga     Idaho State       120         79\n3  11/06/2018   Virginia          Towson        73         42\n4  11/06/2018  Tennessee    Lenoir-Rhyne        86         41",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>win_team</th>\n      <th>lose_team</th>\n      <th>win_score</th>\n      <th>lose_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11/06/2018</td>\n      <td>Kansas</td>\n      <td>Michigan State</td>\n      <td>92</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11/06/2018</td>\n      <td>Duke</td>\n      <td>Kentucky</td>\n      <td>118</td>\n      <td>84</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11/06/2018</td>\n      <td>Gonzaga</td>\n      <td>Idaho State</td>\n      <td>120</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11/06/2018</td>\n      <td>Virginia</td>\n      <td>Towson</td>\n      <td>73</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11/06/2018</td>\n      <td>Tennessee</td>\n      <td>Lenoir-Rhyne</td>\n      <td>86</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "box_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a id=\"Team Ranks Cleaning\">2.2 Team Ranks Cleaning</a>\n",
    "\n",
    "Next we want to look at the ranks dataframe. This data frame is full of missing data, since there are many teams that aren't\n",
    "ranked in the top 25 every week. Many of them dip in and out of the rankings each week. We would also like the indexes be\n",
    "the date instead of the school name. We're going to tidy this data up by creating a new dataframe with the dates as the index,\n",
    "like we desired, and a column for each rank, 1-25, with the columns value as the name of the team of the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "       11/12      11/19     11/26     12/03      12/10      12/17      12/24  \\\n",
      "1       Duke       Duke   Gonzaga   Gonzaga     Kansas     Kansas       Duke   \n",
      "2     Kansas     Kansas    Kansas    Kansas       Duke       Duke   Michigan   \n",
      "3    Gonzaga    Gonzaga      Duke      Duke  Tennessee  Tennessee  Tennessee   \n",
      "4   Virginia   Virginia  Virginia  Virginia    Gonzaga   Michigan   Virginia   \n",
      "5  Tennessee  Tennessee    Nevada  Michigan   Michigan   Virginia     Kansas   \n",
      "\n",
      "       12/31      01/07      01/14      01/21      01/28      02/04  \\\n",
      "1       Duke       Duke       Duke  Tennessee  Tennessee  Tennessee   \n",
      "2   Michigan   Michigan   Michigan       Duke       Duke       Duke   \n",
      "3  Tennessee  Tennessee  Tennessee   Virginia   Virginia   Virginia   \n",
      "4   Virginia   Virginia   Virginia    Gonzaga    Gonzaga    Gonzaga   \n",
      "5     Kansas    Gonzaga    Gonzaga   Michigan   Michigan   Kentucky   \n",
      "\n",
      "       02/11      02/18     02/25      03/04     03/11           Final  \n",
      "1  Tennessee       Duke   Gonzaga    Gonzaga   Gonzaga            Duke  \n",
      "2       Duke    Gonzaga  Virginia   Virginia  Virginia        Virginia  \n",
      "3    Gonzaga   Virginia      Duke        UNC       UNC             UNC  \n",
      "4   Virginia   Kentucky  Kentucky       Duke  Kentucky         Gonzaga  \n",
      "5   Kentucky  Tennessee       UNC  Tennessee      Duke  Michigan State  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "new_ranks = pd.DataFrame(index=[i for i in range(1, 26)])\n",
    "\n",
    "# here we go through each data (and Final) add add the team names into each rank index with a new column for the date\n",
    "for elem in ranks.columns:\n",
    "    if re.match(\"(\\d{1,2}\\/\\d{1,2})|(Final)\", elem):\n",
    "        date_dict = ranks.set_index(\"School\")[elem].dropna().to_dict()\n",
    "        rev_dict = {}\n",
    "        for k, v in date_dict.items():\n",
    "            rev_dict[v] = k\n",
    "\n",
    "        new_ranks[elem] = pd.Series(rev_dict)\n",
    "\n",
    "print(new_ranks.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we've gotten rid of the NA values we can take the tranpose of the data frame to have dates as the index like we wanted\n",
    "We also need to add the date year onto the dates so they correspond with stats dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "                 1       2          3         4          5          6   \\\n",
      "11/12/2018     Duke  Kansas    Gonzaga  Virginia  Tennessee     Nevada   \n",
      "11/19/2018     Duke  Kansas    Gonzaga  Virginia  Tennessee     Nevada   \n",
      "11/26/2018  Gonzaga  Kansas       Duke  Virginia     Nevada  Tennessee   \n",
      "12/03/2018  Gonzaga  Kansas       Duke  Virginia   Michigan     Nevada   \n",
      "12/10/2018   Kansas    Duke  Tennessee   Gonzaga   Michigan   Virginia   \n",
      "\n",
      "                   7          8               9               10  ...  \\\n",
      "11/12/2018        UNC  Villanova          Auburn        Kentucky  ...   \n",
      "11/19/2018        UNC     Auburn        Michigan        Kentucky  ...   \n",
      "11/26/2018   Michigan     Auburn  Michigan State        Kentucky  ...   \n",
      "12/03/2018  Tennessee     Auburn        Kentucky  Michigan State  ...   \n",
      "12/10/2018     Nevada     Auburn  Michigan State   Florida State  ...   \n",
      "\n",
      "                       16                 17                 18          19  \\\n",
      "11/12/2018  Virginia Tech  Mississippi State           Michigan     Clemson   \n",
      "11/19/2018        Clemson               UCLA                TCU         LSU   \n",
      "11/26/2018     Ohio State              Texas             Oregon      Purdue   \n",
      "12/03/2018   Kansas State            Buffalo               Iowa  Ohio State   \n",
      "12/10/2018      Wisconsin          Villanova  Mississippi State    Kentucky   \n",
      "\n",
      "                       20         21                 22          23  \\\n",
      "11/12/2018           UCLA        TCU                LSU      Purdue   \n",
      "11/19/2018           Iowa     Oregon            Buffalo  Ohio State   \n",
      "11/26/2018     Texas Tech    Buffalo          Wisconsin   Villanova   \n",
      "12/03/2018  Arizona State  Villanova  Mississippi State    Maryland   \n",
      "12/10/2018  Arizona State  Marquette               Iowa      Furman   \n",
      "\n",
      "                   24                 25  \n",
      "11/12/2018  Marquette            Buffalo  \n",
      "11/19/2018     Purdue          Wisconsin  \n",
      "11/26/2018   Maryland  Mississippi State  \n",
      "12/03/2018   Nebraska             Furman  \n",
      "12/10/2018    Houston           Syracuse  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "new_ranks = new_ranks.transpose()\n",
    "\n",
    "new_ranks = new_ranks.rename(index=lambda x: re.sub(\"^0.*\", x + \"/2019\", x))\n",
    "new_ranks = new_ranks.rename(index=lambda x: re.sub(\"^1.*\", x + \"/2018\", x))\n",
    "new_ranks = new_ranks.rename(index=lambda x: re.sub(\"Final\", '03/21/2019', x))\n",
    "\n",
    "print(new_ranks.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We should also check to make sure that every date in our ranks column corresponds to a date in the stats dataframe we have\n",
    "so we have easy access between both. We'll use difflib to print out the nearest matches for any dates that aren't found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "12/24/2018\n",
      "['12/28/2018', '12/27/2018', '12/25/2018']\n",
      "02/11/2019\n",
      "['03/11/2019', '02/21/2019', '02/19/2019']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "for date in new_ranks.index:\n",
    "    if date not in dfs.keys():\n",
    "        print(date)\n",
    "        # here we can see candidates\n",
    "        print(difflib.get_close_matches(date, dfs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see there are two dates that don't have a match and there nearest matches in the statistics dataframes. We want to\n",
    "make the ranks correspond to the next date after the ranks have been released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "new_ranks = new_ranks.rename(index=lambda x: re.sub(\"12/24/2018\", '12/25/2018', x))\n",
    "new_ranks = new_ranks.rename(index=lambda x: re.sub(\"02/11/2019\", '02/19/2019', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a id=\"Game Statistics Cleaning\">2.3 Game Statistics Cleaning</a>\n",
    "\n",
    "Finally we need to clean the statistics dataframes themselves. We're going to remove the \"Rank\" column since this is a relic\n",
    "that corresponds to the rank for one of the statistics during each week, and it is not useful information to us.\n",
    "\n",
    "Then, we perform some data cleaning operations on the created dataframes. We choose to convert the W-L column, \n",
    "corresponding to the game wins to losses for a team at a given week, to 3 different columns. The first are the \n",
    " game wins and losses, which are separated to assist later analysis, and then the win percent out of all games played\n",
    " by a team. We then convert the total turn overs for the season into a turn overs per game column. (This is the average\n",
    " of the turn overs for a team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "for date in dfs.keys():\n",
    "    # drop the rank column for each dataframe\n",
    "    if \"Rank\" in dfs[date]:\n",
    "        dfs[date] = dfs[date].drop(\"Rank\", axis=1)\n",
    "    \n",
    "    # create win, win percent column and loss column\n",
    "    WL = dfs[date][\"W-L\"].str.extract(r\"(\\d+)\\-(\\d+)\")\n",
    "    dfs[date][\"Wins\"] = WL[0].astype(float)\n",
    "    dfs[date][\"Losses\"] = WL[1].astype(float)\n",
    "    dfs[date][\"Win%\"] = dfs[date][\"Wins\"]/(dfs[date][\"Losses\"]+dfs[date][\"Wins\"])\n",
    "\n",
    "    # drop columns that are unneeded\n",
    "    dfs[date] = dfs[date].drop(\"W-L\", axis=1)\n",
    "\n",
    "    # change turn overs to be turn overs per game\n",
    "    if \"TO\" in dfs[date]:\n",
    "        dfs[date][\"TO\"] = dfs[date][\"TO\"].astype(float)/(dfs[date][\"Wins\"].astype(float)+dfs[date][\"Losses\"].astype(float))\n",
    "        dfs[date] = dfs[date].rename({\"TO\": \"TOPG\"}, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Maping The Names\">2.4 Maping The Names</a>\n",
    "\n",
    "From the box_scores data and the game statistics data, we can see that some of the names doesn't match up. For example, Florida International in the box scores dataset is have a different name in the game statistics data (FIU). Since we are going to going to use the names as the keys and the box scores to train our predictive model, we need to create a team name maping from the game statistics to box scores. Therefore, if a specific team name in the game statistics doesn't exist in the box scores, we can use the maping to map to the equivalent data. We will do the maping by creating a matches.json file that consist of a dictionary with the maping of the team name **From** the game statistics data **to** the box scores data.\n",
    "\n",
    "1. We will go through the names in the box scores and check whether each name exists in the game statistics dataset\n",
    "2. If there is no match, then we will call the get_close_matches to find the approximate matching\n",
    "3. We will then need to manually check whether there are any names that have no close matches and manually edits them and add their respecrive mapping\n",
    "4. Finally we will replace all the names in the box scores dataset into the equivalent team name in the game statistics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "matches = {}\n",
    "serial_f = \"dfs.dict\"\n",
    "dfs = pickle.load(open(serial_f, 'rb'))\n",
    "scores = pd.read_csv(\"box.csv\")\n",
    "\n",
    "for name in set(scores['win_team'].tolist()):\n",
    "    if name not in dfs['04/08/2019']['Name'].tolist():\n",
    "        closests = difflib.get_close_matches(name, dfs['04/08/2019']['Name'])\n",
    "        if len(closests) == 0:\n",
    "            print(name)\n",
    "        else:\n",
    "            matches[closests[0]] = name\n",
    "\n",
    "js = json.dumps(matches)\n",
    "with open(\"matches\", 'w+') as f:\n",
    "    f.write(js)\n",
    "\n",
    "with open(\"matches.json\", 'r') as j:\n",
    "    matches = json.load(j)\n",
    "\n",
    "matches_rev = {}\n",
    "for k, v in matches.items():\n",
    "    matches_rev[v] = k\n",
    "\n",
    "scores = scores.replace(matches_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><a id=\"Exploratory Data Analysis\">Exploratory Data Analysis</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a id=\"Number One Ranked Teams\">3.1 Number One Ranked Teams</a>\n",
    "\n",
    "Now that are data is tidied it's time for us to look at our data and see if we can find any trends in our data. Let's start\n",
    "by graphing some of the stats for the number one ranked teams for each week and see if there is a trend. If a stat is very\n",
    "important for a team to be ranked number one, we'd expect the value to stay approximately the same from week to week.\n",
    "First we'll check which teams are ranked number one throughout the season to see how varied the position is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rank1s = new_ranks[1]\n",
    "rank1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that there are only 4 different teams during the entire season that hold the number one spot. We'll create a custom\n",
    "legend for each team when graphing so we can get a sense of if stats are jumping around due to different teams holding rank 1\n",
    "or if it's due to other causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Field Goal Percentage Graph\">3.2 Field Goal Percentage Graph</a>\n",
    "\n",
    "Let's start by graphing Field Goal percentage. This is a stat we would expected to have a very strong correlation with win rate,\n",
    "meaning it should stay at a near constant value for rank 1 teams from week to week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "t_cols = {'Duke':'b', 'Gonzaga':'g', 'Kansas':'r', 'Tennessee':'m', 'Average': 'k'}\n",
    "\n",
    "# we need to create a custom legend so points Teams aren't repeated\n",
    "\n",
    "patches = [mpatches.Patch(color=v, label=k) for k, v in t_cols.items()]\n",
    "\n",
    "for index in rank1s.index:\n",
    "    if index in dfs.keys():\n",
    "        curr_y = dfs[index].loc[dfs[index]['Name'] == rank1s[index]]['FG%'].values[0]\n",
    "        plt.scatter(index, curr_y, c=t_cols[rank1s[index]])\n",
    "\n",
    "plt.title('Field Goal Percentage vs Date')\n",
    "plt.legend(handles=patches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### <a id=\"Average Statistics Graph\">3.3 Average Statistics Graph</a>\n",
    "\n",
    "Unfortunately Field Goal Percentage doesn't seem to stay very consistent throughout the season for rank 1. However, we can\n",
    "see that the teams themselves hold consistent numbers during the season. Since we see that not all stats are going to show\n",
    "the entire picture for rank 1, it may be a good idea to also add the average values to try to get a better picture of \n",
    "where the rank 1 teams stats stand. Now we'll graph a few more stats with the average added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stats_to_name = {\"TOPG\" : \"Turn Overs Per Game\",\n",
    "                 \"APG\" : \"Assists Per Game\",\n",
    "                 \"BKPG\" : \"Blocks Per Game\",\n",
    "                 \"RPG\" : \"Rebounds Per Game\",\n",
    "                 \"FG%\" : \"Field Goal Percent\",\n",
    "                 \"OPP FG%\" : \"Opposition Field Goal Percent\",\n",
    "                 \"PFPG\" : \"Personal Fouls Per Game\",\n",
    "                 \"SCR MAR\" : \"Score Margin\",\n",
    "                 \"STPG\" : \"Steals Per Game\",\n",
    "                 \"3FG%\" : \"3-Point Field Goal Percent\",\n",
    "                 \"FT%\" : \"Free Throw Percent\",\n",
    "                 \"REB MAR\" : \"Rebound Margin\",\n",
    "                 \"3PG\" : \"3-Points Per Game\",\n",
    "                 \"Ratio\" : \"Assist to Turnover Ratio\"}\n",
    "stats_to_graph = [\"APG\", \"BKPG\", \"RPG\", \"FG%\", \"PFPG\", \"SCR MAR\", \"STPG\", \"3FG%\"]\n",
    "\n",
    "for stat in stats_to_graph:\n",
    "    dates = []\n",
    "    avgs = []\n",
    "    for index in rank1s.index:\n",
    "        if index in dfs.keys():\n",
    "            dates.append(index)\n",
    "            curr_y = dfs[index].loc[dfs[index]['Name'] == rank1s[index]][stat].values[0]\n",
    "            plt.scatter(index, curr_y, c=t_cols[rank1s[index]])\n",
    "            avgs.append(dfs[index][stat].mean())\n",
    "    plt.plot(dates, avgs, c=t_cols['Average'])\n",
    "    plt.title(stats_to_name[stat])\n",
    "    plt.legend(handles=patches)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From these graphs, if one stat is very important to being rank 1, we'd expect all the teams to have a very similar\n",
    "value for such stats. However it seems all of the stats, except 3-point field goal percentage and rebounds per game,\n",
    "have a very large variations in values for week to week. We can see however that each team tends to keep fairly \n",
    "consistent on each stat from week to week. 3-point field goal percentage being more consistent would lead us to \n",
    "believe this is a more important stat to being rank one than others. \n",
    "\n",
    "We can see that even though the number one ranked team doesn't seem to lean on any one stat they excel comparted to \n",
    "average team in Division 1. There are are a couple stats, such as Steals Per Game, where Tennessee is worse than the\n",
    "average, and 3-point field goal percentage where Duke is below average in the later half of the season, but outside\n",
    "these two occurrences it's clear these teams outperform most of the Division."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Statisics VS Win Percentage\">3.4 Statisics VS Win Percentage</a>\n",
    "\n",
    "We now create multiple scatter plots of a statistic on the x axis, and the win percentages of all the teams on the \n",
    "y axis. We do this by creating a list of statistics we want to plot against win percentage, and then using matplotlib\n",
    "we create multiple plots, each with a unique name. We use dropna() to remove any missing values. Since we only want to \n",
    "view the general trends in the data, it is not important to keep every value to plot the data. We will use the scatter \n",
    "plots to determine which statistics are the best to predict a win for any college basketball team, given certain inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#ranks = pd.read_csv(\"apranks.csv\")\n",
    "\n",
    "serial_f = \"dfs.dict\"\n",
    "dfs = pickle.load(open(serial_f, 'rb'))\n",
    "\n",
    "stats_to_graph = [\"TOPG\", \"APG\", \"BKPG\", \"RPG\", \"FG%\", \"OPP FG%\", \"PFPG\",\n",
    "                  \"SCR MAR\", \"STPG\", \"3FG%\", \"FT%\", \"REB MAR\", \"3PG\", \"Ratio\"]\n",
    "\n",
    "# iterate the stats and make a plot for each one\n",
    "for stat in stats_to_graph:\n",
    "    # get the values for the end of season data, dropping NAN values\n",
    "    plt.scatter(dfs['04/08/2019'][stat].dropna(), dfs['04/08/2019'][\"Win%\"].dropna())\n",
    "\n",
    "    # set the graph labels\n",
    "    plt.xlabel(stats_to_name[stat])\n",
    "    plt.ylabel(\"Win Percent\")\n",
    "    plt.title(stats_to_name[stat] + \" vs Win Percent\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs, it is clear that certain statistics will provide insight to which teams are going to win a game. Some\n",
    "statistics, like score margin (the average amount a team wins a game over the opponent), present a near perfect relation\n",
    "to win percentage. However, this cannot be used in the regression model since it is a data leakage problem (meaning the \n",
    "prediction data implicitly contains the result). This means our predictions would be putting too much value in the \n",
    "results for the score margin. You can read more about data leakage at this link from Towards Data Science. \n",
    "https://towardsdatascience.com/data-leakage-in-machine-learning-10bdd3eec742. \n",
    "\n",
    "Other statistics do not pose such a problem and still show a general trend following the win percentage. Some of these\n",
    "statistics show a negative trend, meaning that the higher the statistic, the more likely it is a team will lose, and \n",
    "others show a positive trend, meaning the higher the statistic the more likely a team is to win. Positive trends are \n",
    "seen in the rebound margin, free throws per game, 3-Point field goal percent, steals per game, assists per game , and \n",
    "blocks per game statistics, while negative trends are shown in the turn overs per games and opposition field goal \n",
    "percent. Some data shows little correlation to the win percent, such as the personal fouls per game and rebounds per \n",
    "game. The statistics with trends will be used later in the predictive regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><a id=\"Machine Learning\">Machine Learning</a></center>\n",
    "\n",
    "Now that we have looked into what our data is and cleaned it up, we can start trying to predict what team will win a game\n",
    "based on it's to date statistics in a given season. The statistics we decided to use for our model are as follows:\n",
    "Blocks per game, Field Goal Percentage, Opponent Field Goal Percentage, Personal Fouls per game, Steals per game, 3 point\n",
    "Field Goal Percentage, Free Throw Percentage, Rebound Margin, and Assist to Turnover ratio.\n",
    "\n",
    "These stats were chosen, because they seemed to have the highest correlation with win rate. You'll notice that we did not\n",
    "include scoring margin in our models inputs even though it had a very strong correlation with win rate.\n",
    "This is because it is an example of data leakage. Data leakage is when we give our model information it shouldn't have \n",
    "make predictions. We shouldn't be giving our model scoring margin, because this statistic has information about if a team\n",
    "is winning or not. We do not want our models to have the information of who won or who lost to do this exact prediction.\n",
    "\n",
    "\n",
    "First we have to prepare our data, by creating x, y pairs. The x values being a list of the statistics from each team, and \n",
    "the y values being which team won. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats_to_use = [\"BKPG\", \"FG%\", \"OPP FG%\", \"PFPG\",\n",
    "                \"STPG\", \"3FG%\", \"FT%\", \"REB MAR\", \"Ratio\"]\n",
    "\n",
    "scores = scores.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#team1, team2, winner, date\n",
    "\n",
    "y_setup = []\n",
    "cross_over = len(scores) / 2\n",
    "for index, row in scores.iterrows():\n",
    "    if index < cross_over:\n",
    "        curr = (row['win_team'], row['lose_team'], 0, row['date'])\n",
    "    else:\n",
    "        curr = (row['lose_team'], row['win_team'], 1, row['date'])\n",
    "    y_setup.append(curr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we need to setup the games so we have some games were team 1 wins, and some where team 2 wins. To do this we will\n",
    "randomize the data, so there is no bias about which teams get picked as team 1 and which get picked as team 2. Then we\n",
    "set the winning team as team 1 for the first half of the dataframe and the losing team as team 1 for the second half. We\n",
    "want to have an even number of each prediction class as to not bias our model to one prediction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = []\n",
    "xs = []\n",
    "for result in y_setup:\n",
    "    date = result[3]\n",
    "    if date not in dfs.keys():\n",
    "        continue\n",
    "    if set(stats_to_use).issubset(set(dfs[date].columns)):\n",
    "\n",
    "        if result[0] not in dfs[date][\"Name\"].values:\n",
    "            continue\n",
    "        if result[1] not in dfs[date][\"Name\"].values:\n",
    "            continue\n",
    "        team1_stats = [dfs[date][dfs[date][\"Name\"] == result[0]][stat].values[0] for stat in stats_to_use]\n",
    "        team2_stats = [dfs[date][dfs[date][\"Name\"] == result[1]][stat].values[0] for stat in stats_to_use]\n",
    "        team1_stats.extend(team2_stats)\n",
    "        xs.append(team1_stats)\n",
    "        y.append(result[2])\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we create the actual x, y pairs. Unfortunately some of the data we recieved from the NCAA website does not contain\n",
    "every team for every week or every stat for every week. So, we need to omit these games from our training since we do not\n",
    "have the information available to us to create inputs for the model. This code simple stacks the stat values for team 1 and \n",
    "team 2 into a list, xs, and the result of the game into a nother list, y. After this, the \n",
    "data is ready to be used to create our regression model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "sv = SVC()\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "svc_score = cross_val_score(sv, xs, y, cv=cv)\n",
    "print(svc_score)\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "lr_score = cross_val_score(lr, xs, y, cv=cv)\n",
    "print(lr_score)\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "rfc_score = cross_val_score(rfc, xs, y, cv=cv)\n",
    "print(rfc_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the data prepared, we can create 3 different models to predict the winner of a basketball game between two \n",
    "teams. We chose 3 regression models for our project. These are a support vector machine, a logistic regression, and a\n",
    "random forest classifier. We then use ShuffleSplit to randomize the data put in the models. The cross validation score\n",
    "tells us how accurate our models were in predicting wins for a basketball game. Based on the results, each model seems\n",
    "to have about 70-percent prediction accuracy. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><a id=\"Conclusion\">Conclusion</a></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Machine learning has become more and more popular. The idea of data science starts from business analysis. Business analysts use statistics to predict and determine whether a decision or a contract will generate profit. From that idea, people started to incorporate data science into other aspects, including sports. People try to build models that can predict whether a certain team will win a game.\n",
    "\n",
    "We started from data collection and data cleaning. This process is the bulk of all data analysis. We need to research different data sets and find ones that we suits our need. We then continue to read the data and clean the data. We use pandas as our primary dataframe because they provide a good representation for the data. We use techniques such as merging, droping and adding columns, mapping, and others to transform our data into something that is interpretable.\n",
    "\n",
    "We then display some graphs to get a view of how the data look like. We use matplotlib as our graphing tool and we made scatter plots to see how the different statistic interact with each other. We saw that some statistics such as field goal percentage did not have a strong correlation. We then graph different statistics with the average and win rate and try to find specific statistics that have a strong correlation with win rate. We then decided that those statistics might be usefull to build our models.\n",
    "\n",
    "After cleaning our data and choosing specific parameters, we can finally build our predictive models. We used our box scores dataset to train our models. We used ScikitLearn and SciPy as our main library because they have a lot of different regression models that we can use. We did logistic regression, random forests, and Support Vector Classification (SVC) which are all models that we use to predict the winning team.\n",
    "\n",
    "Overall there are so much more to explore in the data science world. This tutorial is just a sneak peek into data science in the sports world. Today, we have countless of data for everything and you can definately use the skills in this tutorial for other aspects. If you are interested in learning more about data science in basketball, the https://towardsdatascience.com/tagged/basketball page displays a lot of interesting data science articles on basketball. Thank you so much for reading our tutorial and we hope that this tutorial may spark the inner data scientist in you.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
